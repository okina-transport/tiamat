package org.rutebanken.tiamat.rest.netex.publicationdelivery;

import com.google.common.util.concurrent.ThreadFactoryBuilder;
import com.hazelcast.core.HazelcastInstance;
import org.rutebanken.netex.model.Parking;
import org.rutebanken.netex.model.SiteFrame;
import org.rutebanken.netex.model.StopPlace;
import org.rutebanken.tiamat.importer.restore.RestoringParkingImporter;
import org.rutebanken.tiamat.importer.restore.RestoringStopPlaceImporter;
import org.rutebanken.tiamat.importer.restore.RestoringTopographicPlaceImporter;
import org.rutebanken.tiamat.netex.mapping.NetexMapper;
import org.rutebanken.tiamat.netex.mapping.PublicationDeliveryHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import org.xml.sax.SAXException;

import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.xml.bind.JAXBException;
import javax.xml.parsers.ParserConfigurationException;
import javax.xml.stream.XMLStreamException;
import java.io.IOException;
import java.io.InputStream;
import java.util.List;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.Lock;

@Component
@Produces("application/xml")
@Path("/publication_delivery")
public class RestoringImportResource {

    private static final Logger logger = LoggerFactory.getLogger(RestoringImportResource.class);
    private static final String KEY_INITIAL_IMPORT_LOCK = "initial_import_lock";

    private final PublicationDeliveryPartialUnmarshaller publicationDeliveryPartialUnmarshaller;
    private final NetexMapper netexMapper;
    private final RestoringTopographicPlaceImporter restoringTopographicPlaceImporter;
    private final RestoringParkingImporter restoringParkingImporter;
    private final RestoringStopPlaceImporter restoringStopPlaceImporter;
    private final HazelcastInstance hazelcastInstance;
    private final PublicationDeliveryHelper publicationDeliveryHelper;

    @Autowired
    public RestoringImportResource(PublicationDeliveryPartialUnmarshaller publicationDeliveryPartialUnmarshaller,
                                   NetexMapper netexMapper,
                                   RestoringTopographicPlaceImporter restoringTopographicPlaceImporter,
                                   RestoringStopPlaceImporter restoringStopPlaceImporter,
                                   RestoringParkingImporter restoringParkingImporter,
                                   HazelcastInstance hazelcastInstance, PublicationDeliveryHelper publicationDeliveryHelper) {
        this.publicationDeliveryPartialUnmarshaller = publicationDeliveryPartialUnmarshaller;
        this.netexMapper = netexMapper;
        this.restoringTopographicPlaceImporter = restoringTopographicPlaceImporter;
        this.restoringStopPlaceImporter = restoringStopPlaceImporter;
        this.restoringParkingImporter = restoringParkingImporter;
        this.hazelcastInstance = hazelcastInstance;
        this.publicationDeliveryHelper = publicationDeliveryHelper;
    }

    /**
     * This method requires all incoming data to have IDs that are previously generated by Tiamat and that they are unique.
     * IDs for quays and stop places will not be generated. They will be used as is.
     * TODO: Move this to PublicationDeliveryImporter class
     */
    @POST
    @Path("initial_import")
    @Consumes(MediaType.APPLICATION_XML)
    @Produces(MediaType.TEXT_PLAIN)
    public Response importPublicationDeliveryOnEmptyDatabase(InputStream inputStream) throws IOException, JAXBException, SAXException, XMLStreamException, InterruptedException, ParserConfigurationException {

        Lock lock = hazelcastInstance.getLock(KEY_INITIAL_IMPORT_LOCK);

        if (lock.tryLock()) {
            int threads = Runtime.getRuntime().availableProcessors();
            ExecutorService executorService = Executors.newFixedThreadPool(threads, new ThreadFactoryBuilder().setNameFormat("importer-%d").build());

            try {
                UnmarshalResult unmarshalResult = publicationDeliveryPartialUnmarshaller.unmarshal(inputStream);
                AtomicInteger topographicPlacesCounter = new AtomicInteger();

                SiteFrame netexSiteFrame = publicationDeliveryHelper.findSiteFrame(unmarshalResult.getPublicationDeliveryStructure());
                List<org.rutebanken.netex.model.TopographicPlace> netexTopographicPlaces = publicationDeliveryHelper.extractTopographicPlaces(netexSiteFrame);

                if(netexTopographicPlaces != null) {
                    logger.info("Importing {} topographic places", netexTopographicPlaces.size());
                    restoringTopographicPlaceImporter.importTopographicPlaces(topographicPlacesCounter, netexTopographicPlaces);
                    logger.info("Finished importing {} topographic places", topographicPlacesCounter);
                }

                logger.info("Importing stops");

                AtomicInteger stopPlacesImported = new AtomicInteger(0);

                AtomicBoolean stopStopPlaceExecution = new AtomicBoolean(false);

                for (int i = 0; i < threads; i++) {
                    executorService.submit(() -> {
                        try {
                            while (!Thread.currentThread().isInterrupted() && !stopStopPlaceExecution.get()) {
                                StopPlace stopPlace = unmarshalResult.getStopPlaceQueue().poll(1, TimeUnit.SECONDS);

                                if (stopPlace == null) {
                                    continue;
                                }

                                if (stopPlace.getId().equals(RunnableUnmarshaller.POISON_STOP_PLACE.getId())) {
                                    logger.info("Finished importing stops");
                                    stopStopPlaceExecution.set(true);
                                    break;
                                }

                                restoringStopPlaceImporter.importStopPlace(stopPlacesImported, netexMapper.mapToTiamatModel(stopPlace));
                            }
                        } catch (InterruptedException e) {
                            logger.warn("Interrupted. Stopping all jobs");
                            Thread.currentThread().interrupt();
                            stopStopPlaceExecution.set(true);
                            return;
                        } catch (Exception e) {
                            logger.warn("Caught exception while importing stop", e);
                            stopStopPlaceExecution.set(true);
                        }
                    });
                }

                logger.info("Importing parkings");

                AtomicBoolean stopParkingExecution = new AtomicBoolean(false);
                AtomicInteger parkingsImported = new AtomicInteger(0);

                for (int i = 0; i < threads; i++) {
                    executorService.submit(() -> {
                        try {

                            while (!Thread.currentThread().isInterrupted() && !stopParkingExecution.get()) {
                                Parking parking = unmarshalResult.getParkingQueue().poll(1, TimeUnit.SECONDS);

                                if (parking == null) {
                                    continue;
                                }

                                if (parking.getId().equals(RunnableUnmarshaller.POISON_PARKING.getId())) {
                                    logger.info("Finished importing parking");
                                    stopParkingExecution.set(true);
                                    break;
                                }

                                restoringParkingImporter.importParking(parkingsImported, netexMapper.mapToTiamatModel(parking));
                            }


                        } catch (InterruptedException e) {
                            logger.warn("Interrupted. Stopping all jobs");
                            Thread.currentThread().interrupt();
                            stopParkingExecution.set(true);
                            return;
                        } catch (Exception e) {
                            logger.warn("Caught exception while importing stop", e);
                            stopParkingExecution.set(true);
                        }
                    });
                }

                logger.info("Waiting for all import tasks to finish");

                executorService.shutdown();
                executorService.awaitTermination(150, TimeUnit.MINUTES);

                return Response.ok("Imported " + stopPlacesImported.get() + " stop places, " + parkingsImported.get() + " parkings.").build();

            } catch (Exception e) {
                logger.error("Caught exception while importing publication delivery initially", e);
                executorService.shutdownNow();
                return Response.status(Response.Status.INTERNAL_SERVER_ERROR).entity("Caught exception while import publication delivery: " + e.getMessage()).build();
            } finally {
                lock.unlock();
            }
        }
        return Response.status(Response.Status.CONFLICT).entity("There is already an import job running").build();
    }
}
